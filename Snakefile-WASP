configfile: "config-WASP.yaml"

import glob


def read_samples():
    """Function to get names and fastq paths from a sample file specified
    in the configuration. Input file is expected to have 4 columns:
    <1000genomes_id> <unique_sample_id> <fastq1_path> <fastq2_path>. Modify
    this function as needed to provide a dictionary of sample_id keys and
    (fastq1, fastq1) values"""
    f = open(config['sample_file'], "r")
    samp_dict = {}
    for line in f:
        words = line.strip().split()
        samp_dict[words[1]] = (words[2], words[3])
    return samp_dict


rule all:
    input:
        expand(config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.sort.bam",
               sample=read_samples().keys())

# run the following to execute the pipeline:
# out_path="/iblm/netapp/home/amassarat/allele_specific_analysis/snakemake/out"; snakemake -s Snakefile-WASP --cluster "qsub -t 1 -V -q iblm.q -j y -o ${out_path}/qout" -j 24 --config output_dir=${out_path} --latency-wait 10 --use-conda >>${out_path}/out 2>&1 &

rule split_vcf_by_chr:
    """Split the provided VCF file by chromosome and gzip it for WASP"""
    input:
        vcf = config['vcf_file']
    output:
        dynamic(config['output_dir'] + "/genotypes/ALL.chr{chr_num}.vcf.gz")
    shell:
        "mkdir -p {config[output_dir]}/genotypes && "
        "SnpSift split {input} && "
        "gzip {config[output_dir]}/genotypes/*.vcf"

rule vcf2h5:
    """Convert VCF data files to HDF5 format"""
    input:
        chrom = config['chrom_info'],
        vcfs = rules.split_vcf_by_chr.output
    output:
        snp_index = config['snp_h5_dir'] + "/snp_index.h5",
        snp_tab = config['snp_h5_dir'] + "/snp_tab.h5",
        haplotype = config['snp_h5_dir'] + "/haplotype.h5"
    shell:
        "mkdir -p {config[snp_h5_dir]} && "
        "{config[wasp_dir]}/snp2h5/snp2h5 "
        "  --chrom {input.chrom} "
        "  --format vcf "
        "  --snp_index {output.snp_index} "
        "  --snp_tab {output.snp_tab} "
        "  --haplotype {output.haplotype} "
        "  {input.vcfs}"

rule find_intersecting_snps_paired_end:
    """find intersecting SNPs using WASP script"""
    input:
        bam = config["output_dir"] + "/map1_sort/{sample}.bam",
        snp_index = config["snp_h5_dir"] + "/snp_index.h5",
        snp_tab = config["snp_h5_dir"] + "/snp_tab.h5",
        haplotype = config['snp_h5_dir'] + "/haplotype.h5"
    output:
        fastq1 = config["output_dir"] + "/find_intersecting_snps/{sample}.remap.fq1.gz",
        fastq2 = config["output_dir"] + "/find_intersecting_snps/{sample}.remap.fq2.gz",
        keep_bam = config["output_dir"] + "/find_intersecting_snps/{sample}.keep.bam",
        remap_bam = config["output_dir"] + "/find_intersecting_snps/{sample}.to.remap.bam"
    conda:
        "envs/pytables2.yaml"
    shell:
        "mkdir -p {config[output_dir]}/find_intersecting_snps && "
        "{config[py2]} {config[wasp_dir]}/mapping/find_intersecting_snps.py "
        "    --is_paired_end "
        "    --is_sorted "
        "    --output_dir {config[output_dir]}/find_intersecting_snps "
        "    --snp_tab {input.snp_tab} "
        "    --snp_index {input.snp_index} "
        "    --haplotype {input.haplotype} "
        "    --samples {config[sample_file]} "
        "    {input.bam}"

rule map_STAR_paired_end1:
    """map reads using STAR"""
    input:
        fastq1 = lambda wildcards: read_samples()[wildcards.sample][0],
        fastq2 = lambda wildcards: read_samples()[wildcards.sample][1],
        index = config["ref_genome_star"]
    output:
        config["output_dir"] + "/map1/{sample}/Aligned.sortedByCoord.out.bam"
    params:
        prefix = config["output_dir"] + "/map1/{sample}/"
    shell:
        "mkdir -p {params.prefix} && "
        "{config[STAR]} --runThreadN {threads} "
            "--genomeDir {input.index} "
            "--readFilesIn {input.fastq1} {input.fastq2} "
            "--readFilesCommand zcat --outSAMtype BAM SortedByCoordinate "
            "--outFileNamePrefix {params.prefix}"

rule sort_and_index_bam1:
    """sort and index bam generated by first mapping step"""
    input:
        config["output_dir"] + "/map1/{sample}/Aligned.sortedByCoord.out.bam"
    output:
        config["output_dir"] + "/map1_sort/{sample}.bam",
        config["output_dir"] + "/map1_sort/{sample}.bam.bai"
    shell:
        "mkdir -p {config[output_dir]}/map1_sort && "
        "{config[samtools]} sort -o {output[0]} {input} && "
        "{config[samtools]} index {output[0]}"

rule map_STAR_paired_end2:
    """map reads a second time using STAR"""
    input:
        fastq1 = config['output_dir'] + "/find_intersecting_snps/{sample}.remap.fq1.gz",
        fastq2 = config['output_dir'] + "/find_intersecting_snps/{sample}.remap.fq2.gz",
        index = config["ref_genome_star"]
    output:
        config["output_dir"] + "/map2/{sample}/Aligned.sortedByCoord.out.bam"
    params:
        prefix = config["output_dir"] + "/map2/{sample}/"
    shell:
        "mkdir -p {params.prefix} && "
        "{config[STAR]} --runThreadN {threads} "
            "--genomeDir {input.index} "
            "--readFilesIn {input.fastq1} {input.fastq2} "
            "--readFilesCommand zcat --outSAMtype BAM SortedByCoordinate "
            "--outFileNamePrefix {params.prefix}"

rule sort_and_index_bam2:
    """sort and index bam generated by second mapping step"""
    input:
        config["output_dir"] + "/map2/{sample}/Aligned.sortedByCoord.out.bam"
    output:
        config["output_dir"] + "/map2_sort/{sample}.bam",
        config["output_dir"] + "/map2_sort/{sample}.bam.bai"
    shell:
        "mkdir -p {config[output_dir]}/map2_sort && "
        "{config[samtools]} sort -o {output[0]} {input} && "
        "{config[samtools]} index {output[0]}"

rule filter_remapped_reads:
    """filter reads from second mapping step"""
    input:
        to_remap_bam = config['output_dir'] + "/find_intersecting_snps/{sample}.to.remap.bam",
        remap_bam = config['output_dir'] + "/map2_sort/{sample}.bam",
    output:
        keep_bam = config['output_dir'] + "/filter_remapped_reads/{sample}.keep.bam"
    shell:
        "mkdir -p {config[output_dir]}/filter_remapped_reads && "
        "{config[py2]} {config[wasp_dir]}/mapping/filter_remapped_reads.py "
        "  {input.to_remap_bam} {input.remap_bam} {output.keep_bam}"

rule merge_bams:
    """merge 'keep' BAM files from mapping steps 1 and 2, then sort and index"""
    input:
        keep1 = config['output_dir'] + "/find_intersecting_snps/{sample}.keep.bam",
        keep2 = config['output_dir'] + "/filter_remapped_reads/{sample}.keep.bam"
    output:
        merge = config['output_dir'] + "/merge/{sample}.keep.merge.bam",
        sort = config['output_dir'] + "/merge/{sample}.keep.merge.sort.bam"
    shell:
        "mkdir -p {config[output_dir]}/merge && "
        "{config[samtools]} merge {output.merge} {input.keep1} {input.keep2} && "
        "{config[samtools]} sort -o {output.sort} {output.merge} && "
        "{config[samtools]} index {output.sort}"

rule rmdup_pe:
    """remove duplicate read pairs"""
    input:
        config['output_dir'] + "/merge/{sample}.keep.merge.sort.bam"
    output:
        rmdup = config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.bam",
        sort = config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.sort.bam"
    shell:
        "mkdir -p {config[output_dir]}/rmdup && "
        "{config[py2]} {config[wasp_dir]}/mapping/rmdup_pe.py {input} {output.rmdup} && "
        "{config[samtools]} sort -o {output.sort} {output.rmdup} && "
        "{config[samtools]} index {output.sort}"
