configfile: "config-variant_calling.yaml"


def read_samples():
    """Function to get names and fastq paths from a sample file specified
    in the configuration. Input file is expected to have 4 columns:
    <1000genomes_id> <unique_sample_id> <fastq1_path> <fastq2_path>. Modify
    this function as needed to provide a dictionary of sample_id keys and
    (fastq1, fastq1) values"""
    f = open(config['sample_file'], "r")
    samp_dict = {}
    for line in f:
        words = line.strip().split()
        samp_dict[words[1]] = (words[2], words[3])
    return samp_dict


"""WASP needs some config values. Let's load them, so the user doesn't
have to."""
config['snp_h5_dir'] = config['output_dir'] + "/genotypes/snp_h5"


rule all:
    input:
        config['output_dir'] + "/genotypes/ALL.vcf.gz"

# run the following to execute the pipeline:
# out_path="/iblm/netapp/home/amassarat/allele_specific_analysis/snakemake/out"; snakemake -s Snakefile-variant_calling --cluster "qsub -t 1 -V -q iblm.q -j y -o ${out_path}/qout" -j 24 --config output_dir=${out_path} --latency-wait 10 >>${out_path}/out 2>&1 &

rule align_dna:
    """Align DNA reads using BWA-MEM. Note that we use -R to specify read group
    info for haplotype caller."""
    input:
        ref = config['ref_genome_bwa'],
        fastq1 = lambda wildcards: read_samples()[wildcards.sample][0],
        fastq2 = lambda wildcards: read_samples()[wildcards.sample][1]
    output:
        config['output_dir'] + "/dna_align/{sample}.sam"
    threads: config['num_threads']
    shell:
        "{config[bwa]} mem -M "
        "-R '@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}\\tPL:ILLUMINA' "
        "-t {threads} {input.ref} "
        "{input.fastq1} {input.fastq2} > {output}"

rule sam_to_bam:
    """Convert a SAM file to its more compressed counterpart. Note that -u to
    create an uncompressed bam file. We use -q to filter alignments with MAPQ
    scores less than 20."""
    input:
        rules.align_dna.output
    output:
        config['output_dir'] + "/dna_align/{sample}.raw.bam"
    threads: config['num_threads']
    shell:
        "{config[samtools]} view -u -b -F 4 -q 20 -@ {threads} {input} >{output}"

rule sort_bam_by_name:
    """Sort the bam output by name (not by coordinates yet)"""
    input:
        rules.sam_to_bam.output
    output:
        config['output_dir'] + "/dna_align/{sample}.nameSort.bam"
    threads: config['num_threads']
    shell:
        "{config[samtools]} sort -n -@ {threads} {input} >{output}"

rule add_mate_info:
    """Use fixmate to fill in mate coordinates and mate related flags, since
    our data is pair-ended. We need the MC tags (included because we used the
    -m flag) that it creates for markdup"""
    input:
        rules.sort_bam_by_name.output
    output:
        config['output_dir'] + "/dna_align/{sample}.mate.nameSort.bam"
    threads: config['num_threads']
    shell:
        "{config[samtools]} fixmate -m -@ {threads} {input} {output}"

rule sort_bam_by_coord:
    """Sort the bam output by coordinates. Needed for markdup use later on."""
    input:
        rules.add_mate_info.output
    output:
        config['output_dir'] + "/dna_align/{sample}.coordSort.mate.nameSort.bam"
    threads: config['num_threads']
    shell:
        "{config[samtools]} sort -@ {threads} -o {output} {input}"

rule rm_dups:
    """Remove duplicates that may have occurred from PCR and index the
    resulting file."""
    input:
        rules.sort_bam_by_coord.output
    output:
        final_bam = config['output_dir'] + "/dna_align/{sample}.final.bam",
        final_bam_index = config['output_dir'] + "/dna_align/{sample}.final.bam.bai"
    threads: config['num_threads']
    shell:
        "mkdir -p {config[output_dir]}/dna_align && "
        "{config[samtools]} markdup -@ {threads} {input} {output.final_bam} && "
        "{config[samtools]} index -b -@ {threads} {output.final_bam}"

rule base_recal:
    """Recalibrate the base quality scores. They might be biased"""
    input:
        ref = config['ref_genome'],
        bam = rules.rm_dups.output.final_bam,
        known_sites = config['dbSNP']
    output:
        config['output_dir'] + "/base_recal/{sample}.recal_data.table"
    shell:
        "mkdir -p {config[output_dir]}/base_recal && "
        "{config[gatk]} BaseRecalibrator -R {input.ref} -I {input.bam} -known-sites {input.known_sites} -O {output}"

rule apply_base_recal:
    """Apply base quality score recalibration"""
    input:
        ref = config['ref_genome'],
        bam = rules.rm_dups.output.final_bam,
        recal_table = rules.base_recal.output
    output:
        config['output_dir'] + "/base_recal/{sample}.recal.final.bam"
    shell:
        "{config[gatk]} ApplyBQSR -R {input.ref} -I {input.bam} --bqsr-recal-file {input.recal_table} -O {output}"

rule haplotype:
    """Make a file with annotated variants"""
    input:
        ref = config['ref_genome'],
        bam = rules.apply_base_recal.output
    output:
        config['output_dir'] + "/haplotype/{sample}.snps.g.vcf.gz"
    shell:
        "{config[gatk]} HaplotypeCaller "
        "-R {input.ref} -I {input.bam} -O {output} -ERC GVCF "
        "-G StandardAnnotation -G AS_StandardAnnotation -G StandardHCAnnotation"

rule combine:
    """Combine the g.vcf files"""
    input:
        ref = config['ref_genome'],
        vcf = expand(rules.haplotype.output, sample=read_samples().keys())
    output:
        config['output_dir'] + "/haplotype/ALL.g.vcf.gz"
    run:
        vcf_params = " ".join(['-V '+file for file in input.vcf])
        shell(("{config[gatk]} CombineGVCFs -R {input.ref} -O {output} "
               "-G StandardAnnotation -G AS_StandardAnnotation "
               + vcf_params))

rule genotype:
    """Perform joint genotyping on all of the samples"""
    input:
        ref = config['ref_genome'],
        vcf = rules.combine.output
    output:
        config['output_dir'] + "/haplotype/ALL.genotype.vcf.gz"
    shell:
        "{config[gatk]} GenotypeGVCFs -R {input.ref} -V {input.vcf} -O {output} "
        "-G StandardAnnotation -G AS_StandardAnnotation"

rule variant_filter:
    """Filter variants by QD, FS, MQ, MQRankSum, ReadPosRankSum, and SOR"""
    input:
        ref = config['ref_genome'],
        vcf = rules.genotype.output,
        hapmap = config['hapmap'],
        omni = config['omni'],
        project1000G = config['1000G'],
        dbsnp = config['dbSNP']
    output:
        recal = config['output_dir'] + "/variant_filter/ALL.recal",
        tranches = config['output_dir'] + "/variant_filter/ALL.tranches"
    shell:
        "mkdir -p {config[output_dir]}/variant_filter && "
        "{config[gatk]} VariantRecalibrator -R {input.ref} -V {input.vcf} "
        "--resource hapmap,known=false,training=true,truth=true,prior=15.0:{input.hapmap} "
        "--resource omni,known=false,training=true,truth=false,prior=12.0:{input.omni} "
        "--resource 1000G,known=false,training=true,truth=false,prior=10.0:{input.project1000G} "
        "--resource dbsnp,known=true,training=false,truth=false,prior=2.0:{input.dbsnp} "
        "-an QD -an FS -an MQ -an MQRankSum -an ReadPosRankSum -an SOR "
        "-mode SNP -O {output.recal} --tranches-file {output.tranches}"

rule apply_variant_filter:
    """Create a file with only variants that have passed filtration"""
    input:
        ref = config['ref_genome'],
        vcf = rules.genotype.output,
        recal = rules.variant_filter.output.recal,
        tranches = rules.variant_filter.output.tranches
    output:
        config['output_dir'] + "/variant_filter/ALL.filter.vcf.gz"
    shell:
        "{config[gatk]} ApplyVQSR -R {input.ref} -V {input.vcf} -mode SNP "
        "--ts-filter-level 97.5 --recal-file {input.recal} "
        "--tranches-file {input.tranches} -O {output}"

rule filter_hets:
    """Extract heterozygotes from the filtered VCF file"""
    input:
        vcf = rules.apply_variant_filter.output
    output:
        config['output_dir'] + "/genotypes/ALL.vcf.gz"
    shell:
        "zcat {input} | "
        "{config[SnpSift]} filter \"(countHet() > 0) && (FILTER == 'PASS')\" | "
        "gzip -c >{output}"
