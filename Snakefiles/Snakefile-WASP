import glob
from pathlib import Path
from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("5.18.0")


# check existence of SAMP variable. it may have already been defined if this
# Snakefile is being included from somewhere else
if 'SAMP2' not in globals():
    def read_samples():
        """Function to get names and fastq paths from a sample file specified
        in the configuration. Input file is expected to have 4 columns:
        <vcf_sample_id> <unique_sample_id> <fastq1_path> <fastq2_path>. Modify
        this function as needed to provide a dictionary of sample_id keys and
        (fastq1, fastq1) values"""
        f = open(config['sample_file'], "r")
        samp_dict = {}
        for line in f:
            words = line.strip().split("\t")
            samp_dict[words[1]] = (words[2], words[3])
        return samp_dict
    SAMP2 = read_samples()

# the user can change config['SAMP_NAMES'] here (or define it in the config
# file) to contain whichever sample names they'd like to run the pipeline on
if 'SAMP_NAMES' not in config:
    config['SAMP_NAMES'] = list(SAMP2.keys())

# check existence of SAMP_TO_VCF_ID. it may have already been defined if this
# Snakefile is being included from somewhere else
if 'SAMP_TO_VCF_ID' not in globals():
    def read_vcf_samples():
        f = open(config['sample_file'], "r")
        samp_dict = {}
        for line in f:
            words = line.strip().split("\t")
            if words[1] in config['SAMP_NAMES']:
                samp_dict[words[1]] = words[0]
        return samp_dict
    SAMP_TO_VCF_ID = read_vcf_samples()


if not hasattr(rules, 'all'):
    rule all:
        # if you'd like to run the pipeline on only a subset of the samples,
        # you should specify them in the config['SAMP_NAMES'] variable above
        input:
            expand(config['output_dir'] + "/rmdup/{sample}.keep.rmdup.sort.bam",
                   sample=config['SAMP_NAMES'])

include: "snp2h5_rules.smk"

rule map_STAR_paired_end1:
    """map reads using STAR"""
    input:
        fastq1 = lambda wildcards: SAMP2[wildcards.sample][0],
        fastq2 = lambda wildcards: SAMP2[wildcards.sample][1],
        index = config['ref_genome_star']
    params:
        prefix = config['output_dir'] + "/map1/{sample}/"
    output:
        temp(str(Path(config['output_dir']).absolute()) + "/map1/{sample}/Aligned.out.bam")
    conda: "../envs/default.yaml"
    shell:
        "STAR --runThreadN 1 "
            "--genomeDir {input.index} "
            "--readFilesIn {input.fastq1} {input.fastq2} "
            "--readFilesCommand zcat "
            "--outSAMtype BAM Unsorted "
            "--alignEndsType EndToEnd "
            "--outFileNamePrefix {params.prefix}"

rule sort_and_index_bam1:
    """sort and index bam generated by first mapping step"""
    input:
        rules.map_STAR_paired_end1.output
    output:
        bam = config['output_dir'] + "/map1_sort/{sample}.bam",
        index = config['output_dir'] + "/map1_sort/{sample}.bam.bai"
    conda: "../envs/default.yaml"
    shell:
        "samtools sort -o {output.bam} {input} && "
        "samtools index {output.bam} && "
        "touch -c {output.bam}"

rule find_intersecting_snps_paired_end:
    """find intersecting SNPs using WASP script"""
    input:
        bam = rules.sort_and_index_bam1.output.bam,
        snp_index = rules.vcf2h5.output.snp_index,
        snp_tab = rules.vcf2h5.output.snp_tab,
        haplotype = rules.vcf2h5.output.haplotype,
        find_intersecting_snps_script = rules.get_WASP.output.find_intersecting_snps_script
    params:
        sample_names = lambda wildcards: SAMP_TO_VCF_ID[wildcards.sample]
    output:
        fastq1 = config['output_dir'] + "/find_intersecting_snps/{sample}.remap.fq1.gz",
        fastq2 = config['output_dir'] + "/find_intersecting_snps/{sample}.remap.fq2.gz",
        keep_bam = temp(config['output_dir'] + "/find_intersecting_snps/{sample}.keep.bam"),
        remap_bam = config['output_dir'] + "/find_intersecting_snps/{sample}.to.remap.bam"
    conda: "../envs/default.yaml"
    shell:
        "python {input.find_intersecting_snps_script} "
            "--is_paired_end "
            "--is_sorted "
            "--output_dir {config[output_dir]}/find_intersecting_snps "
            "--snp_tab {input.snp_tab} "
            "--snp_index {input.snp_index} "
            "--haplotype {input.haplotype} "
            "--samples {params.sample_names} "
            "{input.bam}"

rule map_STAR_paired_end2:
    """map reads a second time using STAR"""
    input:
        fastq1 = rules.find_intersecting_snps_paired_end.output.fastq1,
        fastq2 = rules.find_intersecting_snps_paired_end.output.fastq2,
        index = config['ref_genome_star']
    params:
        prefix = config['output_dir'] + "/map2/{sample}/"
    output:
        temp(str(Path(config['output_dir']).absolute()) + "/map2/{sample}/Aligned.out.bam")
    conda: "../envs/default.yaml"
    shell:
        "STAR --runThreadN 1 "
            "--genomeDir {input.index} "
            "--readFilesIn {input.fastq1} {input.fastq2} "
            "--readFilesCommand zcat "
            "--outSAMtype BAM Unsorted "
            "--alignEndsType EndToEnd "
            "--outFileNamePrefix {params.prefix}"

rule sort_and_index_bam2:
    """sort and index bam generated by second mapping step"""
    input:
        rules.map_STAR_paired_end2.output
    output:
        bam = config['output_dir'] + "/map2_sort/{sample}.bam",
        index = config['output_dir'] + "/map2_sort/{sample}.bam.bai"
    conda: "../envs/default.yaml"
    shell:
        "samtools sort -o {output.bam} {input} && "
        "samtools index {output.bam} && "
        "touch -c {output.bam}"

rule filter_remapped_reads:
    """filter reads from second mapping step"""
    input:
        to_remap_bam = rules.find_intersecting_snps_paired_end.output.remap_bam,
        remap_bam = rules.sort_and_index_bam2.output.bam,
        filter_remapped_reads_script = rules.get_WASP.output.filter_remapped_reads_script
    output:
        temp(config['output_dir'] + "/filter_remapped_reads/{sample}.keep.bam")
    conda: "../envs/default.yaml"
    shell:
        "python {input.filter_remapped_reads_script} "
        "{input.to_remap_bam} {input.remap_bam} {output}"

rule sort_filtered_bam:
    """sort 'keep' BAM file from rules.filter_remapped_reads for rules.rmdup_pe"""
    input:
        rules.filter_remapped_reads.output
    output:
        config['output_dir'] + "/filter_remapped_reads/{sample}.keep.sort.bam"
    conda: "../envs/default.yaml"
    shell:
        "samtools sort -o {output} {input} && "
        "samtools index {output}"

rule rmdup_pe:
    """remove duplicate read pairs"""
    input:
        bam = rules.sort_filtered_bam.output,
        rmdup_script = rules.get_WASP.output.rmdup_script
    output:
        rmdup = temp(config['output_dir'] + "/rmdup/{sample}.keep.rmdup.bam"),
        sort = config['output_dir'] + "/rmdup/{sample}.keep.rmdup.sort.bam"
    conda: "../envs/default.yaml"
    shell:
        "python {input.rmdup_script} {input.bam} {output.rmdup} && "
        "samtools sort -o {output.sort} {output.rmdup} && "
        "samtools index {output.sort} && "
        "touch -c {output.sort}"
