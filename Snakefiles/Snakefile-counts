import glob
from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("5.1.4")

configfile: "config-counts.yaml"


# check existence of SAMP variable. it may have already been defined if this
# Snakefile is being included from somewhere else
if 'SAMP' not in globals():
    def read_samples():
        """Function to get names and fastq paths from a sample file specified
        in the configuration. Input file is expected to have 4 columns:
        <vcf_sample_id> <unique_sample_id> <dna_bam_path> <rna_bam_path>. Modify
        this function as needed to provide a dictionary of sample_id keys and
        (fastq1, fastq1) values"""
        f = open(config['sample_file'], "r")
        samp_dict = {}
        for line in f:
            words = line.strip().split("\t")
            samp_dict[words[1]] = (words[2], words[3])
        return samp_dict
    SAMP = read_samples()

# the user can change config['SAMP_NAMES'] here (or define it in the config
# file) to contain whichever sample names they'd like to run the pipeline on
if 'SAMP_NAMES' not in config:
    config['SAMP_NAMES'] = list(SAMP.keys())

# check existence of SAMP_TO_VCF_ID. it may have already been defined if this
# Snakefile is being included from somewhere else
if 'SAMP_TO_VCF_ID' not in globals():
    def read_vcf_samples():
        f = open(config['sample_file'], "r")
        samp_dict = {}
        for line in f:
            words = line.strip().split("\t")
            if words[1] in config['SAMP_NAMES']:
                samp_dict[words[1]] = words[0]
        return samp_dict
    SAMP_TO_VCF_ID = read_vcf_samples()


rule all:
    input:
        # if you'd like to run the pipeline on only a subset of the samples,
        # you should specify them in the config['SAMP_NAMES'] variable above
        expand(config['output_dir'] + "/final/{sample}/result.csv.gz",
               sample=config['SAMP_NAMES'])

# run the following to execute the pipeline:
# out_path="/iblm/netapp/home/amassarat/allele_specific_analysis/snakemake/out"; snakemake -s Snakefile-counts --cluster "qsub -t 1 -V -q iblm.q -j y -o ${out_path}/qout" -j 24 --config output_dir=${out_path} --latency-wait 60 --use-conda >>${out_path}/out 2>&1 &

rule extract_gq_scores:
    """Create a table containing GQ scores for each sample from the input vcf.
    The file will have columns: CHROM, POS, REF, ALT, and GEN[{sample}].GQ"""
    input:
        vcf = config['vcf_file']
    params:
        samples = ' '.join("'GEN[{0}].GQ'".format(w) for samp in list(SAMP_TO_VCF_ID.values()))
    output:
        config['output_dir'] + "/extract_gq/gq_subset.tsv.gz"
    conda: "envs/default.yaml"
    shell:
        "SnpSift extractFields {input.vcf} 'CHROM' 'POS' 'REF' 'ALT' "
        "{params.samples} | gzip >{output}"

rule split_vcf_by_chr:
    """Split the provided VCF file by chromosome and gzip it for WASP"""
    input:
        vcf = config['vcf_file']
    output:
        dynamic(config['output_dir'] + "/genotypes/ALL.chr{chr_num}.vcf.gz")
    conda: "envs/default.yaml"
    shell:
        "SnpSift split {input} && "
        "gzip {config[output_dir]}/genotypes/*.vcf"

rule vcf2h5:
    """Convert VCF data files to HDF5 format"""
    input:
        chrom = config['chrom_info'],
        vcfs = rules.split_vcf_by_chr.output
    output:
        snp_index = config['snp_h5_dir'] + "/snp_index.h5",
        snp_tab = config['snp_h5_dir'] + "/snp_tab.h5",
        haplotype = config['snp_h5_dir'] + "/haplotype.h5"
    conda: "envs/pytables2.yaml"
    shell:
        "{config[wasp_dir]}/snp2h5/snp2h5 "
        "  --chrom {input.chrom} "
        "  --format vcf "
        "  --snp_index {output.snp_index} "
        "  --snp_tab {output.snp_tab} "
        "  --haplotype {output.haplotype} "
        "  {input.vcfs}"

rule get_as_counts:
    """get allele-specific read counts for SNPs"""
    input:
        bam = lambda wildcards: SAMP[wildcards.sample][wildcards.type == "rna"],
        snp_index = rules.vcf2h5.output.snp_index,
        snp_tab = rules.vcf2h5.output.snp_tab,
        haplotype = rules.vcf2h5.output.haplotype,
    params:
        sample_names = lambda wildcards: SAMP_TO_VCF_ID[wildcards.sample]
    output:
        config['output_dir'] + "/as_counts/{sample}/{type}.as_counts.txt.gz"
    conda: "envs/pytables2.yaml"
    shell:
        "python {config[wasp_dir]}/mapping/get_as_counts.py "
        "  --snp_tab {input.snp_tab} "
        "  --snp_index {input.snp_index} "
        "  --haplotype {input.haplotype} "
        "  --samples {params.sample_names} "
        "  --genotype_sample {params.sample_names} "
        "  {input.bam} | grep '0|1' | gzip > {output}"

rule remove_indel_counts:
    """remove indels from the counts files"""
    input:
        rules.get_as_counts.output
    output:
        config['output_dir'] + "/as_counts/{sample}/{type}.as_counts.snps.txt.gz"
    shell:
        "{config[Rscript]} --vanilla scripts/remove_indels.r {input} "
        "| gzip >{output}"

rule prepare_counts:
    """prepare counts for detecting imbalance, adding gene info
    and calculating genotype error"""
    input:
        dna_counts = expand(rules.remove_indel_counts.output,
                            sample=config['SAMP_NAMES'], type=["dna"]),
        rna_counts = expand(rules.remove_indel_counts.output,
                            sample=config['SAMP_NAMES'], type=["rna"]),
        gq_file = rules.extract_gq_scores.output,
        gene_info = config['gene_info']
    params:
        samples = config['SAMP_NAMES'],
        gq_name = [SAMP_TO_VCF_ID[samp] for samp in config['SAMP_NAMES']],
        sample_file = config['output_dir'] + "/final/samples.tsv",
        output_dir = config['output_dir'] + "/final/"
    output:
        expand(config['output_dir'] + "/final/{sample}/dna.csv.gz",
               sample=config['SAMP_NAMES']),
        expand(config['output_dir'] + "/final/{sample}/rna.csv.gz",
               sample=config['SAMP_NAMES'])
    run:
        sample_file = open(output[0], 'w+')
        for i in range(len(params.samples)):
            sample_file.write("\t".join([params.samples[i],
                                         input.dna_counts[i],
                                         input.rna_counts[i],
                                         params.gq_name[i]]) + "\n")
        sample_file.close()
        shell("{config[Rscript]} --no-save --no-restore scripts/prepare_counts.r {input.sample_file} {input.gene_info} {input.gq_file} {params.output_dir}")

rule detect_imbalance:
    """quantify allelic imbalance in genes for each sample"""
    input:
        dna = config['output_dir'] + "/final/{sample}/dna.csv.gz",
        rna = config['output_dir'] + "/final/{sample}/rna.csv.gz",
        gene_info = config['gene_info']
    params:
        imbalance_script_path = "scripts/allele_imbalance.r"
    output:
        config['output_dir'] + "/final/{sample}/result.csv.gz"
    shell:
        "{config[Rscript]} --no-save --no-restore scripts/find_imbalance.r "
        "{params.imbalance_script_path} {input.dna} {input.rna} {input.gene_info} "
        "| gzip >{output}"
